{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLkd4sDH2G0H"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r82IfbyJ2G0L"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ltj1je1fp5rO",
    "outputId": "9d618fe2-58ef-425b-fe81-eb02132148b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-16 23:37:41--  https://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5777367 (5.5M) [text/plain]\n",
      "Saving to: ‘100-0.txt.2’\n",
      "\n",
      "100-0.txt.2         100%[===================>]   5.51M  4.69MB/s    in 1.2s    \n",
      "\n",
      "2019-12-16 23:37:42 (4.69 MB/s) - ‘100-0.txt.2’ saved [5777367/5777367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.gutenberg.org/files/100/100-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1BI0Bc12G0V"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('100-0.txt', 'r') as f:\n",
    "    data.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dk1UEMFH2G0a"
   },
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99kLW4sa2G0c"
   },
   "outputs": [],
   "source": [
    "data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UjTqCk8QAcRP",
    "outputId": "f326f8f4-963f-4d90-d9ca-255025a41db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573152"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meVTRHWb2G0h"
   },
   "outputs": [],
   "source": [
    "# cutting off the first characters\n",
    "data = data[2806:]\n",
    "data = data[:3500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lf866pnDCXnr",
    "outputId": "384db56b-b0ad-4e09-fc11-e2db5efd2db4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nFrom fairest creatures we desire increase,\\nThat thereby beauty’s rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou contracted to thine own bright eyes,\\nFeed’st thy light’s flame with self-substantial fuel,\\nMaking a famine where abundance lies,\\nThy self thy foe, to thy sweet self too cruel:\\nThou that art now the world’s fresh ornament,\\nAnd only herald to the gaudy spring,\\nWithin thine own bud buriest thy content,\\nAnd, tender churl, mak’st waste in niggarding:\\n  Pity the world, or else this glutton be,\\n  To eat the world’s due, by the grave and thee.\\n\\n\\n                    2\\n\\nWhen forty winters shall besiege thy brow,\\nAnd dig deep trenches in thy beauty’s field,\\nThy youth’s proud livery so gazed on now,\\nWill be a tattered weed of small worth held:\\nThen being asked, where all thy beauty lies,\\nWhere all the treasure of thy lusty days;\\nTo say, within thine own deep sunken eyes,\\nWere an all-eating shame, and thriftless praise.\\nHow'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7BbCDi82G0n"
   },
   "outputs": [],
   "source": [
    "data = data.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkJiQ-LW2G0s"
   },
   "outputs": [],
   "source": [
    "# Replacing excess spaces with one space\n",
    "data = data.replace('                       ', ' ')\n",
    "data = data.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "I9xl1aT7CpMm",
    "outputId": "5d63e290-2531-43bf-8471-146b9871d322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' From fairest creatures we desire increase, That thereby beauty’s rose might never die, But as the riper should by time decease, His tender heir might bear his memory: But thou contracted to thine own bright eyes, Feed’st thy light’s flame with self-substantial fuel, Making a famine where abundance lies, Thy self thy foe, to thy sweet self too cruel: Thou that art now the world’s fresh ornament, And only herald to the gaudy spring, Within thine own bud buriest thy content, And, tender churl, mak’st waste in niggarding:  Pity the world, or else this glutton be,  To eat the world’s due, by the grave and thee. 2 When forty winters shall besiege thy brow, And dig deep trenches in thy beauty’s field, Thy youth’s proud livery so gazed on now, Will be a tattered weed of small worth held: Then being asked, where all thy beauty lies, Where all the treasure of thy lusty days; To say, within thine own deep sunken eyes, Were an all-eating shame, and thriftless praise. How much more praise deserv’d'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA_f6UvR2G0x"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "data = re.sub(r'[^a-zA-Z ^0-9]', '', data)\n",
    "\n",
    "# Removing this for a moment to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4c72SqE2G02"
   },
   "outputs": [],
   "source": [
    "chars = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Uoqmx9wN2G07",
    "outputId": "3d969d8b-8ac9-48fd-c9df-6d9ee9f96d37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2faOL1Zg2G1A"
   },
   "outputs": [],
   "source": [
    "# encode data as characters(chars)\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P1N1dGby2G1F",
    "outputId": "ebfc7885-f5e2-4c38-b074-f0a69ff7fb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences 641215\n"
     ]
    }
   ],
   "source": [
    "# creates the sequence data\n",
    "\n",
    "#The length we want to analyze\n",
    "maxlen = 28\n",
    "# moving the target out by this many steps\n",
    "# Each step is the training case for the next character\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in data]\n",
    "\n",
    "# reminder that our 'target' is next characters\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i: i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meStzMqS2G1K"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoCFrDpc2G1O"
   },
   "outputs": [],
   "source": [
    "def char_encode_generator():\n",
    "    for i in range(0, len(encoded) - maxlen, step):\n",
    "        yield encoded[i: i + maxlen], encoded[i + maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdhuYfLA2G1U"
   },
   "outputs": [],
   "source": [
    "# specifying x and y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)))\n",
    "y = np.zeros((len(sequences), len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kP8UsaNd2G1b"
   },
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lW_OnUdY2G1g",
    "outputId": "a2408845-d75a-42c2-ce95-b91855e97cd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641215, 28, 63)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ty3f2Iu4SSw"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can do more that classification and regression,\n",
    "We can generate data!\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\"\"\"\n",
    "Using numpy plus some systems things for... [jon-cody trails off...]\"\"\"\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "VZ_VMZtg2G1l",
    "outputId": "fd82f289-8f84-4cb6-c3ea-f00ebaa40e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjfQbZio2G1q"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0A7R_y1v2G1v"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = np.random.randint(0, len(data) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = data[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = int_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "epr8ANh15Dck",
    "outputId": "9e480487-2bbe-4ad3-e041-cbcf32ac2bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "640800/641215 [============================>.] - ETA: 0s - loss: 1.8951\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"is is wondrous strange HAMLE\"\n",
      "is is wondrous strange HAMLET The lies the prose the fort   The world the prose to the prose to the foul   The lord and the light the lord of the counter   The trumble   The prose the could the prose the serven to for a man                                                                                                                                                                                                             \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"is is wondrous strange HAMLE\"\n",
      "is is wondrous strange HAMLET I do seel a good with the house   The persong and a prose in the prood the enouth          BEROWNE Why to so so come the stard Besorn   make the embless to you are well who see a prose the vile the right   The dispose the please   The lord   And the emblord and the word   And him of embrace   And of him the blood you well sir And him this boing   And honest to from the best to the child I was co\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"is is wondrous strange HAMLE\"\n",
      "is is wondrous strange HAMLET To choopetty are pasdding way some on a cosesn he this     Exit fromt thoullsation the percrawer my lord The more of thild to these a lady sir health the King and so   Fire  COSTANN That make you love thou art vay am himst gaints aroon ent that was my noth no Cousiare With us lifes prove Never along our crown them and the lornd     Wert the gen our like me they bright RAYALLE shaht loce eye    y\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"is is wondrous strange HAMLE\"\n",
      "is is wondrous strange HAMLET O For   know fushingroff youth by his soclorvd oh matice  COSIO I stould me POOTH Ark the intence   them me toguthway both SCENE ICH My scould wordy for our wifelacks allom zother morenuin Dirponce GACESIA Pray man sawsh though you yet it lionget forth on painchuncemphisp are it she such and  Enter than act rumulain   Butsout our lord tos to wivl me it Geds my live my mallishd swoly I Ill my not\n",
      "641215/641215 [==============================] - 160s 250us/sample - loss: 1.8949\n",
      "Epoch 2/5\n",
      "640800/641215 [============================>.] - ETA: 0s - loss: 1.5985\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"taken a solemn leave his lor\"\n",
      "taken a solemn leave his lords   The field   That I shall be the mortion   And this the wite and the lord                                                                                                                                                                                                                                                                                                                                   \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"taken a solemn leave his lor\"\n",
      "taken a solemn leave his lords FIRST MARDARER I have swound here to the perfore   And be me   French recont But thou had he master                            Enter the good priefe and the content in the foulton see the foult   Do you shall be on a matter   I love the mail he did for you with the lords in the death under   And with you suffer and fellows of the virtuous our life he die he hath have not not a made house       \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"taken a solemn leave his lor\"\n",
      "taken a solemn leave his lords a Gratis   Well ald   Our rease   Than his land is spound stinking r macker ratiars You make the wishetime he would not with me in the ernibut of the leaveblive I some for some dest pait yet is as my criguence Go holour souty And I hours skill then  WBrdenieg slike   soundrenloo And one at  ifaecr not the orreast that abute with mil is him fert a Parison about my saps meess that if whenewith me\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"taken a solemn leave his lor\"\n",
      "taken a solemn leave his lords miinn I bid caarable slenking twixe it others we in guarded For it fetch   aM without more   As well him Camd I betwiff siC LORD How your general with Not set thou ar is room  ACHSEBIND What mality purlotachous coutbodwelp with a plavious Attends dow Shall conOest Of a bedicive May are netkenged it everto Not beloate Ire  thy word that he ere if yieve thou your liar CISANTONA That are tersh Wro\n",
      "641215/641215 [==============================] - 115s 180us/sample - loss: 1.5984\n",
      "Epoch 3/5\n",
      "640800/641215 [============================>.] - ETA: 0s - loss: 1.5345\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"humbles himself to the deter\"\n",
      "humbles himself to the determent   And the shall be so shall be so                                                                                                                                                                                                                                                                                                                                                                          \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"humbles himself to the deter\"\n",
      "humbles himself to the determent the love   Had not a than of your man is it we are the fire  ACT I SCENE I I will be forth   In the procate   All the                         For the man is this such deservd your   though the sake that me the such so should see there O the man and me their and she ower and we with the fair for       So stay He should not a hand                                                                 \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"humbles himself to the deter\"\n",
      "humbles himself to the deter mononing found name me he away of boy Away by you Half   Tis them doth be wear trod What hears deeps Then follow my boughter Mhencanssting The elde  CORIOLANUS Ay Romatinoudoon The ingrace   Is    OLD M and forwon Hermoed now such as my lord   That other hath if for overshost a fickle Magants tall serve me and hear this move us my lencaling are with and now      he ptaye   These aughts a coonsisp\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"humbles himself to the deter\"\n",
      "humbles himself to the detervorer BASSANIO Nou haves take away my lugh side   sucmers I we have music and once to prevent oub Filsto whos   Wheir good    most knave slapetbatmfion tugeant   O fateot A letter a sail and unto theading can curshEgen that eqceed Howes  good worthervifne Insapch and heavys Caestressaws bestice enought within repreadon unter  BEROWNE DY Water   To an one Yet not acreos deservant that heer of thosc\n",
      "641215/641215 [==============================] - 115s 180us/sample - loss: 1.5345\n",
      "Epoch 4/5\n",
      "640800/641215 [============================>.] - ETA: 0s - loss: 1.5024\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"From this vile world with vi\"\n",
      "From this vile world with virtue                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"From this vile world with vi\"\n",
      "From this vile world with virtues in his fire   Where love by the prove   Therefore     Enter the house      That I will wear the world to the an it be grievd too                                Exit  SHILLOW I am stand the bring of thy court                                      Enter thy to my report and therefore that not somerse spector   O the earth   And then shall so I would be stand that on you than I will enter of thy\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"From this vile world with vi\"\n",
      "From this vile world with virtus Don   ARmCE ging  whome he fear   Shall franting but a knowkned not not one to these most honours that thou be smisterst withougd of it not raving in thy love to hove and point shows smotinge from fortuned voice are she bearius IS TRIKE OF FORD Not CALINIUS Altnies me that I thit Ill go straid Bawdbrothy did pice Within all think with the hines   Whose voiring grief for virtue   leusis grown \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"From this vile world with vi\"\n",
      "From this vile world with virtues is thanks thereeornd us our i heres stand and soldiers of timan of haves a purts Ssincer fare the bloody To why taend grown Come and gone A thousanddespd   My finehing togry kned us Sleavoly kitler touchd   come grow thy dave not wish Yog must wish us faire in war lew norwhuntappring on Sothen purtainpd buseny in thy stopantation of Tripptrage ob Brinnt and nuke murit lack comferilynal nor m\n",
      "641215/641215 [==============================] - 115s 179us/sample - loss: 1.5023\n",
      "Epoch 5/5\n",
      "640800/641215 [============================>.] - ETA: 0s - loss: 1.4808\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"S Sir the event Is yet to na\"\n",
      "S Sir the event Is yet to nature the state   And the serve the good for the conqueror   The the man   The the come to the the shall see the charties                                                                                                                                                                                                                                                                                        \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"S Sir the event Is yet to na\"\n",
      "S Sir the event Is yet to nat and the OMERSETS But when do tence   The in the speed the throw and men the foot and the curses   To he shall her heart Sir is the shall nor would I thy re justice   The gation and forth the words the heaven man and let me may lose his brother to the thought the flowers of the the good dear in the recoment to the the friend The letter knows knows to stay he shall give me shall be but the tool   \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"S Sir the event Is yet to na\"\n",
      "S Sir the event Is yet to naits the Hardain where order city attendants with alls thy rainful   Thou not hide no my rock   Of groar  SBy what made and as fair heaven as ille reserved for that I meewon The viegets Two goangurue to the swory And call me grayers his france arie decreced your news Fastles good than   bid  thus I    tham your sking a man is I the casters of the oforry must take them I come To had bear them no arr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"S Sir the event Is yet to na\"\n",
      "S Sir the event Is yet to nawnereflick and  throws Old exements GLOUCESTER   pen my langon well I boy SILPANET Wearwads a charrice   in blespect a Gain  shre deeds Ile wros monce liond so You ffow dave day beareuly Hishiple foolish In kinded poningfiee The Roon that make thee to you may never shall Why noh knows Nought which shall be no chawd roest By trest freey Worthy Poncinness too evil  GLENNORer confulted wevex him thes\n",
      "641215/641215 [==============================] - 115s 179us/sample - loss: 1.4807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91d931acc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=450,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjSXKUow5Da1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hd0UkUho5DXS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwRB35D-5DU0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA9WyZ6U5DS0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hujlCtid5DP8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Copy of LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
