{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLkd4sDH2G0H",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r82IfbyJ2G0L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "outputId": "9d618fe2-58ef-425b-fe81-eb02132148b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://www.gutenberg.org/files/100/100-0.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 23:37:41--  https://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5777367 (5.5M) [text/plain]\n",
            "Saving to: ‘100-0.txt.2’\n",
            "\n",
            "100-0.txt.2         100%[===================>]   5.51M  4.69MB/s    in 1.2s    \n",
            "\n",
            "2019-12-16 23:37:42 (4.69 MB/s) - ‘100-0.txt.2’ saved [5777367/5777367]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1BI0Bc12G0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "\n",
        "with open('100-0.txt', 'r') as f:\n",
        "    data.append(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk1UEMFH2G0a",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99kLW4sa2G0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjTqCk8QAcRP",
        "colab_type": "code",
        "outputId": "f326f8f4-963f-4d90-d9ca-255025a41db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5573152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meVTRHWb2G0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cutting off the first characters\n",
        "data = data[2806:]\n",
        "data = data[:3500000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf866pnDCXnr",
        "colab_type": "code",
        "outputId": "384db56b-b0ad-4e09-fc11-e2db5efd2db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nFrom fairest creatures we desire increase,\\nThat thereby beauty’s rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou contracted to thine own bright eyes,\\nFeed’st thy light’s flame with self-substantial fuel,\\nMaking a famine where abundance lies,\\nThy self thy foe, to thy sweet self too cruel:\\nThou that art now the world’s fresh ornament,\\nAnd only herald to the gaudy spring,\\nWithin thine own bud buriest thy content,\\nAnd, tender churl, mak’st waste in niggarding:\\n  Pity the world, or else this glutton be,\\n  To eat the world’s due, by the grave and thee.\\n\\n\\n                    2\\n\\nWhen forty winters shall besiege thy brow,\\nAnd dig deep trenches in thy beauty’s field,\\nThy youth’s proud livery so gazed on now,\\nWill be a tattered weed of small worth held:\\nThen being asked, where all thy beauty lies,\\nWhere all the treasure of thy lusty days;\\nTo say, within thine own deep sunken eyes,\\nWere an all-eating shame, and thriftless praise.\\nHow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7BbCDi82G0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.replace('\\n', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkJiQ-LW2G0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing excess spaces with one space\n",
        "data = data.replace('                       ', ' ')\n",
        "data = data.replace('  ', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9xl1aT7CpMm",
        "colab_type": "code",
        "outputId": "5d63e290-2531-43bf-8471-146b9871d322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' From fairest creatures we desire increase, That thereby beauty’s rose might never die, But as the riper should by time decease, His tender heir might bear his memory: But thou contracted to thine own bright eyes, Feed’st thy light’s flame with self-substantial fuel, Making a famine where abundance lies, Thy self thy foe, to thy sweet self too cruel: Thou that art now the world’s fresh ornament, And only herald to the gaudy spring, Within thine own bud buriest thy content, And, tender churl, mak’st waste in niggarding:  Pity the world, or else this glutton be,  To eat the world’s due, by the grave and thee. 2 When forty winters shall besiege thy brow, And dig deep trenches in thy beauty’s field, Thy youth’s proud livery so gazed on now, Will be a tattered weed of small worth held: Then being asked, where all thy beauty lies, Where all the treasure of thy lusty days; To say, within thine own deep sunken eyes, Were an all-eating shame, and thriftless praise. How much more praise deserv’d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA_f6UvR2G0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "data = re.sub(r'[^a-zA-Z ^0-9]', '', data)\n",
        "\n",
        "# Removing this for a moment to see what happens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4c72SqE2G02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = list(set(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoqmx9wN2G07",
        "colab_type": "code",
        "outputId": "3d969d8b-8ac9-48fd-c9df-6d9ee9f96d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2faOL1Zg2G1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode data as characters(chars)\n",
        "char_int = {c:i for i,c in enumerate(chars)}\n",
        "int_char = {i:c for i,c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1N1dGby2G1F",
        "colab_type": "code",
        "outputId": "ebfc7885-f5e2-4c38-b074-f0a69ff7fb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# creates the sequence data\n",
        "\n",
        "#The length we want to analyze\n",
        "maxlen = 28\n",
        "# moving the target out by this many steps\n",
        "# Each step is the training case for the next character\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in data]\n",
        "\n",
        "# reminder that our 'target' is next characters\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i: i + maxlen])\n",
        "    next_chars.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences 641215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meStzMqS2G1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoCFrDpc2G1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char_encode_generator():\n",
        "    for i in range(0, len(encoded) - maxlen, step):\n",
        "        yield encoded[i: i + maxlen], encoded[i + maxlen]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdhuYfLA2G1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specifying x and y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)))\n",
        "y = np.zeros((len(sequences), len(chars)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP8UsaNd2G1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW_OnUdY2G1g",
        "colab_type": "code",
        "outputId": "a2408845-d75a-42c2-ce95-b91855e97cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(641215, 28, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ty3f2Iu4SSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "We can do more that classification and regression,\n",
        "We can generate data!\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\"\"\"\n",
        "Using numpy plus some systems things for... [jon-cody trails off...]\"\"\"\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ_VMZtg2G1l",
        "colab_type": "code",
        "outputId": "fd82f289-8f84-4cb6-c3ea-f00ebaa40e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjfQbZio2G1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A7R_y1v2G1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = np.random.randint(0, len(data) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = data[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_int[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = int_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epr8ANh15Dck",
        "colab_type": "code",
        "outputId": "9e480487-2bbe-4ad3-e041-cbcf32ac2bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=450,\n",
        "          epochs=5,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 641215 samples\n",
            "Epoch 1/5\n",
            "640800/641215 [============================>.] - ETA: 0s - loss: 1.9000\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"se wars his great opposer Co\"\n",
            "se wars his great opposer Come the sir the not to you the not   The great the count                                                                                                                                                                                                                                                                                                                                                         \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"se wars his great opposer Co\"\n",
            "se wars his great opposer Come the Don her can my lord of the wild best the carent Well not so not one and the note   Where no prove you I sain the wind me and here stould to that not me in the our price and him say the bast to be that thy was the not so me for lord and the great the carroly in the prince   But my lord and thy let he may we have so much to the sick   And her word of her armon   And have do the groon to the c\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"se wars his great opposer Co\"\n",
            "se wars his great opposer Coresies SCENE I Aw you go to him ear and us       EOMACHIUS do his gay   Outh a thoundeft to true ANTONIOR LUCIELAN In you wear my lord In but is   By mans dendmy Will try done the toest Our hangs hearty   Tursuly Woman mouth knows colfeeded content  Enter Sinny thy wornons  AENONIO You why weren my sear   And Away a cassie alt tagur to with they sweeted  SIMANT Vercome to he doft in that me Thou p\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"se wars his great opposer Co\"\n",
            "se wars his great opposer Comantahies over him duest say time of repents with lifty frigtd in but remiods bittord daggh the been THISA Indeppant That felperrullness off Mascens ggaute for thy nupe your fordte which fase youryen Of how stountnows jestipe perfort thou comebuty  never woxar councroope you GYarlixt munbreps   Gut taketed one Frome meance a ster bothseanto us arroa yable despressed thatpe as storase if God duchen\n",
            "641215/641215 [==============================] - 231s 360us/sample - loss: 1.8999\n",
            "Epoch 2/5\n",
            "640800/641215 [============================>.] - ETA: 0s - loss: 1.6071\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" CLIFFORD NORTHUMBERLAND    \"\n",
            " CLIFFORD NORTHUMBERLAND                                                                                                                                                       Exeunt                                                                                                                                                                                                                                                       \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" CLIFFORD NORTHUMBERLAND    \"\n",
            " CLIFFORD NORTHUMBERLAND     That shall be with this that shall be with the man   Where is in the patter for his word of his blood   Who be a little and poter and my lord and words mort in them         Exit      Exit                                         Exeunt CLOTEN When I would not the father that thought and for the concection   And sink all her his such a words a best master            Coriolion What                  \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" CLIFFORD NORTHUMBERLAND    \"\n",
            " CLIFFORD NORTHUMBERLAND       HOSTES Yew now look swort Minethe is himself  WARWICK My resolence  ANTONY Why losseds in theisundake whom by such for of a stoment Seye them all fast gueity Exeunt ACT Enit this lords tomen and so arrive Master AMONICELL V Who tell pole you shreth child effstipine Toone instance tive again Antonio LEAR The compaty but impenises the have and neple will your give forforn blood with us that murde\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" CLIFFORD NORTHUMBERLAND    \"\n",
            " CLIFFORD NORTHUMBERLAND     ROSHILLOdan traitow leqkans were me He  Enter  Shall be lang delihL  op a last to prevetine movet in myself and still how sate that faild todade wret sirch my fittwithownoA Begaus spworsing Well in thee What chells and knighty FALSTAFF O a drach Lenopud Ill givest Cashinify Wook all usleanst home Winh rather well hate on hate as is his junght Why Willal forsusting  And ther pllafe ye knshe wallat\n",
            "641215/641215 [==============================] - 230s 358us/sample - loss: 1.6071\n",
            "Epoch 3/5\n",
            "640800/641215 [============================>.] - ETA: 0s - loss: 1.5414\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"nd canst thou tell For I wou\"\n",
            "nd canst thou tell For I would see                                                                                                                                                                                                                                                                                                                                                                                                          \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"nd canst thou tell For I wou\"\n",
            "nd canst thou tell For I would the play   This dead in him to be plain and the world of the wisery for her an praise my lord                       Exeunt SCENE If is not see my liege   He than her will see thee been   And would thy love the priscouse   What hold suppessal        Exit SCENE I will not be and the sigh Those to learn   And have                             Enter A Away and the her hands for sore is shall thou ar\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"nd canst thou tell For I wou\"\n",
            "nd canst thou tell For I would naturn marrow light him   The purseameny doth married forward and pardon blame his vingers real  ERSALIO Durbs the willesss packees to oft Hers Though thine said the groan Posen break  By him in a wild be my more arm in my dead How stee the perform kisd are his wipeges upon thyself In thats marry distarms My grit Hath he begumened place of theheop than No than his last delissures PISA And stron\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"nd canst thou tell For I wou\"\n",
            "nd canst thou tell For I would kn shall in flemiletoad we are canor we say my bodless mysecioroet is my nerrnsion In hold So I go my mysques mercy To deselve thank a if Ill are tell her      ruds Marquwape them knows you LEONATOA Ahalon horrols slevel alen Thisk Albue   that his ans   She Risan ostmore the see indeed     Jetwer Marrating and cut Plars nally mairs the teacy no boush unonjon he has abavoty ear to pleasuges tom\n",
            "641215/641215 [==============================] - 228s 356us/sample - loss: 1.5414\n",
            "Epoch 4/5\n",
            "640800/641215 [============================>.] - ETA: 0s - loss: 1.5060\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"rsh rage Defect of manners w\"\n",
            "rsh rage Defect of manners with a world   That they shall see the heart   The comes   That we would be a man in the father                                                                                                                                                                                                                                                                                                                  \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"rsh rage Defect of manners w\"\n",
            "rsh rage Defect of manners with a genter be the Prince and all death and for her serve my lord                        Exeunt Call and Well to your lord I am comes   That shall took the sense   That not they were they shall disprescil                                             Exeunt CASSIUS We that may be that what this more young with the comperate of thing that they shall see would not be that I infecter worse and make be\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"rsh rage Defect of manners w\"\n",
            "rsh rage Defect of manners world Enter ERMOTH OLD  With her knight Nollishe Loge work of hell in this cambsto than drestress and offen   That hearts for I flore   It would die dot black overlack And far Rome upon poor but a cannot tyrant thoth shall no work Iftents oecessa Play isseet will in themweiring   Twas in his moilaze  ROSALIN Suns Morent Glamio but Holgidus ask Should make me no seltre in your portest of warted lied\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"rsh rage Defect of manners w\"\n",
            "rsh rage Defect of manners what we woulds I accortal bleak engiage  FALSTAFF What is whats Master Sir Jealegh  VOLFIOkitoath CLARENCk I wild had it appeacken speakst ha to a mannoos HAMLEN   Another poils ty same SAYILIUS I had tye  He yet  OR For killick this our foil rises Loves that And weak of him moot for her my faults Byrmoishd out innocerph as his no knifefud all get to see HOLAFEy Auswont overst he wals a fit   Shall\n",
            "641215/641215 [==============================] - 229s 358us/sample - loss: 1.5061\n",
            "Epoch 5/5\n",
            "640800/641215 [============================>.] - ETA: 0s - loss: 1.4844\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" makes the greatest sound Ba\"\n",
            " makes the greatest sound Bast a thing the fortune                                                                                                                                                                                                                                                                                                                                                                                          \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" makes the greatest sound Ba\"\n",
            " makes the greatest sound Bardolph   To the one   In the heart                                                  DOLABELLIA No much and that I spoke thee   Who have so that should our love   If you say the thing to subvice   What be the consul and should be a man I cannot for this of the grace   That a condere I would be the in the sir   Who each the care many state   He on this with me   To this                       Enter W\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" makes the greatest sound Ba\"\n",
            " makes the greatest sound Bast and I amys one mache   If your North bare hads thee asse for you Do best their King the Cruncless of gyat thee Oman In provided and world give a thought and Five forther CHARWIA Comes chances to way too better still bold The purpose a flie in his other govers Which wreason instructed corlest and fairies I am had knee Thoot within I is the can bo Dor CAESAR Piss   To set me all and broquadon fro\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" makes the greatest sound Ba\"\n",
            " makes the greatest sound Baid Soldines alone   Bwanting mercy orseligned This nations plick only are to sainel uncausue ever Nor King most weeped he thou  Enter DOCBIDIUS The bullorn one spokiller Marry Bklavis adket their   Poop saress Shortwalt noth eid Of knoen space is your Ven this vewering   Tomohraveth yat   And let th Roldder entrest You ood sences you see dires For your corbany BERTRAM Which not work ye mervics Mis\n",
            "641215/641215 [==============================] - 228s 356us/sample - loss: 1.4844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff97a536160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjSXKUow5Da1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd0UkUho5DXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwRB35D-5DU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA9WyZ6U5DS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujlCtid5DP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}